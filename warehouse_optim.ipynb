{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from enum import Enum, auto\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "import mdptoolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "TRAINING_DATASET_PATH = 'data/warehousetraining.txt'\n",
    "TEST_DATASET_PATH = 'data/warehouseorder.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "WAREHOUSE_SIZE = 4\n",
    "WAREHOUSE_LAYOUT = (2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Action = namedtuple('Action', ['operation_type','item_type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OperationType(Enum):\n",
    "    STORE = auto()\n",
    "    RESTORE = auto()\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_str(value):\n",
    "        if value.upper() == 'STORE':\n",
    "            return OperationType.STORE\n",
    "        elif value.upper() == 'RESTORE':\n",
    "            return OperationType.RESTORE\n",
    "        else:\n",
    "            raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemType(Enum):\n",
    "    WHITE = auto()\n",
    "    BLUE = auto()\n",
    "    RED = auto()\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_str(value):\n",
    "        if value.upper() == 'WHITE':\n",
    "            return ItemType.WHITE\n",
    "        elif value.upper() == 'BLUE':\n",
    "            return ItemType.BLUE\n",
    "        elif value.upper() == 'RED':\n",
    "            return ItemType.RED\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    @staticmethod\n",
    "    def list():\n",
    "        return list(ItemType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarehouseDataSet:\n",
    "    \n",
    "    def __init__(self, path=TRAINING_DATASET_PATH):\n",
    "        self.path = path\n",
    "        self.dataset = pd.read_csv(path, sep='\\t', names=['OperationType', 'ItemType'])\n",
    "        self.rel_freq = self._create_rel_freq_dict(self.dataset)\n",
    "        self.size = self.dataset.shape[0]\n",
    "        \n",
    "    def _create_rel_freq_dict(self, dataset: pd.DataFrame):\n",
    "        rel_freq_series = (dataset.value_counts() / dataset.shape[0])\n",
    "        tmp_dict = rel_freq_series.to_dict()\n",
    "        rel_freq_dict = {}\n",
    "        for (operation, item), rel_freq in tmp_dict.items():\n",
    "            operation_type = OperationType.from_str(operation)\n",
    "            item_type = ItemType.from_str(item) \n",
    "            a = Action(operation_type, item_type)\n",
    "            rel_freq_dict[a] = rel_freq\n",
    "            #rel_freq_dict[(operation_type, item_type)] = rel_freq\n",
    "        return rel_freq_dict\n",
    "\n",
    "    def get_relative_frequency_for(self, action: (OperationType, ItemType)):\n",
    "        return self.rel_freq.get(action, 0)\n",
    "\n",
    "    def get_relative_frequencies(self):\n",
    "        return self.rel_freq.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WarehouseDataSet(TRAINING_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Warehouse:\n",
    "     \n",
    "    @staticmethod\n",
    "    def is_applicable_action(position, s, s_prime):\n",
    "        action = s[1]\n",
    "        cell_content_s = s[0][position]\n",
    "        cell_content_s_prime = s_prime[0][position]\n",
    "        is_applicable = False\n",
    "        if action.operation_type == OperationType.STORE:\n",
    "            is_applicable = cell_content_s is None and cell_content_s_prime == action.item_type\n",
    "        elif action.operation_type == OperationType.RESTORE:\n",
    "            is_applicable = cell_content_s == action.item_type and cell_content_s_prime is None\n",
    "        else:\n",
    "            raise ValueError()\n",
    "        return is_applicable\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_distance(position, layout):\n",
    "        # Since the robot can not go diagonally\n",
    "        # it makes sense to use the manhattan distance + 1 for the outside position\n",
    "        manhattan_distance = sum(np.unravel_index(position, layout))\n",
    "        return 1 + manhattan_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transition_probability_matrix(dataset, state_space):\n",
    "    number_of_states = len(state_space)\n",
    "    tpm = np.zeros((WAREHOUSE_SIZE, number_of_states, number_of_states), dtype=np.float16)\n",
    "    for position in range(WAREHOUSE_SIZE): \n",
    "        for x, s in enumerate(state_space):\n",
    "            for y, s_prime in enumerate(state_space):\n",
    "                if Warehouse.is_applicable_action(position, s, s_prime):\n",
    "                    tpm[position, x, y] = dataset.get_relative_frequency_for(s[1])\n",
    "            # handle dead states\n",
    "            if tpm[position, x].sum() == 0:\n",
    "                tpm[position, x, x] = 1.0\n",
    "        tpm[position] = tpm[position] / tpm[position].sum(axis=1)[:, None]    \n",
    "    return tpm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionSpace:\n",
    "\n",
    "    def __init__(self, operation_enum, item_type_enum):\n",
    "        self.operation_enum = operation_enum\n",
    "        self.item_type_enum = item_type_enum\n",
    "    \n",
    "    def get(self):\n",
    "        action_space = []\n",
    "        for o_type, i_type in product(list(self.operation_enum), list(self.item_type_enum)):\n",
    "            action_space.append(Action(o_type, i_type))\n",
    "        return action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StateSpace:\n",
    "    \n",
    "    def __init__(self, operation_enum, item_type_enum, number_of_cells, action_space):\n",
    "        self.number_of_cells = number_of_cells\n",
    "        self.operation_enum = operation_enum\n",
    "        self.item_type_enum = item_type_enum\n",
    "        self.possible_cell_states = [None] + list(item_type_enum)\n",
    "        self.warehouse_states = product(self.possible_cell_states, repeat=self.number_of_cells)\n",
    "        self.action_space = action_space\n",
    "        \n",
    "    def get(self):\n",
    "        return list(product(self.warehouse_states, self.action_space))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state_space():\n",
    "    from itertools import product\n",
    "    states_space = []\n",
    "    possible_cell_states = [None, ItemType.RED, ItemType.WHITE, ItemType.BLUE]\n",
    "    warehouse_state_space = product(possible_cell_states, repeat=4)\n",
    "    possible_actions = []\n",
    "    t = product(list(OperationType), list(ItemType))\n",
    "    for operation_type, item_type in t:\n",
    "        possible_actions.append(Action(operation_type, item_type))\n",
    "    return list(product(warehouse_state_space, possible_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RewardStructure:\n",
    "    \n",
    "    def __init__(self, reward_for_dead_ends, position_rewards, weights):\n",
    "        self.reward_for_dead_ends = reward_for_dead_ends\n",
    "        self.position_reward_mapping = {}\n",
    "        for pos, reward in position_rewards:\n",
    "            self.position_reward_mapping[pos] = reward\n",
    "        self.weights = weights\n",
    "\n",
    "    def calculate_reward(self, position, s):\n",
    "        cell_content = s[0][position]\n",
    "        action = s[1]\n",
    "        reward = self.reward_for_dead_ends\n",
    "        weight = self.get_weight_factor_for_action(action)\n",
    "        if action.operation_type == OperationType.STORE:\n",
    "            if cell_content is None:\n",
    "                reward = self.position_reward_mapping.get(position) * weight\n",
    "        elif action.operation_type == OperationType.RESTORE:\n",
    "            if cell_content == action.item_type:\n",
    "                reward = self.position_reward_mapping.get(position) * weight\n",
    "        else:\n",
    "            raise ValueError\n",
    "        return reward\n",
    "        \n",
    "    def create_reward_matrix(self, dataset, state_space):\n",
    "        number_of_states = len(state_space)\n",
    "        rm = np.zeros((WAREHOUSE_SIZE, number_of_states), dtype=np.float16)\n",
    "        for position in range(WAREHOUSE_SIZE):\n",
    "            for x, s in enumerate(state_space):\n",
    "                rm[position, x] = self.calculate_reward(position, s) \n",
    "        return rm.T\n",
    "            \n",
    "    def get_weight_factor_for_action(self, action):\n",
    "        return self.weights.get(action, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the transition probabilty matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_space = ActionSpace(OperationType, ItemType).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_space = StateSpace(OperationType, ItemType, WAREHOUSE_SIZE, action_space).get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_probability_matrix = create_transition_probability_matrix(train_dataset, state_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the reward matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "position_rewards = []\n",
    "for pos in range(WAREHOUSE_SIZE):\n",
    "    reward = - Warehouse.calculate_distance(pos, WAREHOUSE_LAYOUT)\n",
    "    position_rewards.append((pos, reward))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {}\n",
    "for action, rel_freq in train_dataset.get_relative_frequencies().items(): \n",
    "    weights[action] = 1 + rel_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw = RewardStructure(-10, position_rewards, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_matrix = rw.create_reward_matrix(train_dataset, state_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy-Iteration Algorithm:\n",
      "[0 0 0 ... 0 0 0]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0\n",
      "Value-Iteration Algorithm:\n",
      "None\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "DISCOUNT_FACTOR = 0.99\n",
    "ITERATIONS = 100\n",
    "policy_iteration_result = mdptoolbox.mdp.PolicyIteration(\n",
    "    transition_probability_matrix,\n",
    "    reward_matrix,\n",
    "    DISCOUNT_FACTOR, \n",
    "    max_iter=ITERATIONS\n",
    ")\n",
    "value_iteration_result = mdptoolbox.mdp.ValueIteration(\n",
    "    transition_probability_matrix,\n",
    "    reward_matrix, \n",
    "    DISCOUNT_FACTOR, \n",
    "    max_iter=ITERATIONS\n",
    ")\n",
    "\n",
    "#policy_iteration_result.run()\n",
    "#value_iteration_result.run()\n",
    "\n",
    "print('Policy-Iteration Algorithm:')\n",
    "print(policy_iteration_result.policy)\n",
    "print(policy_iteration_result.V)\n",
    "print(policy_iteration_result.iter)\n",
    "\n",
    "print('Value-Iteration Algorithm:')\n",
    "print(value_iteration_result.policy)\n",
    "print(value_iteration_result.V)\n",
    "print(value_iteration_result.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
